{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EncoderBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Z1ODakYZZnG5"
      ],
      "authorship_tag": "ABX9TyNmLH3GAaH9QCtUExVC9wn0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter Sentiment Analysis\n",
        "\n",
        "**HuggingFace's transformers library to fine-tune pretrained BERT model for a classification task.**"
      ],
      "metadata": {
        "id": "7CNm4F5rMx7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "aZQ0KFFlMsUC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eee9HJuTNAEX",
        "outputId": "259bd7ef-51d0-40b7-e202-da788164260e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/My Drive/HuggingFaceTrain\""
      ],
      "metadata": {
        "id": "K49sylqVPshY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "0uDGiGChP_fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "JSGZrtXdQAie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path+'/Corona_NLP_train.csv', encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "U5SVmBIhV38J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset('csv', data_files={'train': path+'/Corona_NLP_train.csv'}, encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "B6mOWakFPtuE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "TZkDdmhDQQ1I",
        "outputId": "9e4097a6-2404-469d-f525-3e7a4a280f1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b788f57c-8035-4ea1-afe0-8ae5697751a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>44951</td>\n",
              "      <td>89903</td>\n",
              "      <td>Wellington City, New Zealand</td>\n",
              "      <td>14-04-2020</td>\n",
              "      <td>Airline pilots offering to stock supermarket s...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>44952</td>\n",
              "      <td>89904</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14-04-2020</td>\n",
              "      <td>Response to complaint not provided citing COVI...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>44953</td>\n",
              "      <td>89905</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14-04-2020</td>\n",
              "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>44954</td>\n",
              "      <td>89906</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14-04-2020</td>\n",
              "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>44955</td>\n",
              "      <td>89907</td>\n",
              "      <td>i love you so much || he/him</td>\n",
              "      <td>14-04-2020</td>\n",
              "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41157 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b788f57c-8035-4ea1-afe0-8ae5697751a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b788f57c-8035-4ea1-afe0-8ae5697751a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b788f57c-8035-4ea1-afe0-8ae5697751a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       UserName  ...           Sentiment\n",
              "0          3799  ...             Neutral\n",
              "1          3800  ...            Positive\n",
              "2          3801  ...            Positive\n",
              "3          3802  ...            Positive\n",
              "4          3803  ...  Extremely Negative\n",
              "...         ...  ...                 ...\n",
              "41152     44951  ...             Neutral\n",
              "41153     44952  ...  Extremely Negative\n",
              "41154     44953  ...            Positive\n",
              "41155     44954  ...             Neutral\n",
              "41156     44955  ...            Negative\n",
              "\n",
              "[41157 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentiment into integer and tokenize the tweets\n",
        "def transform_labels(label):\n",
        "    num = 0\n",
        "    if label == 'Positive':\n",
        "      num = 0\n",
        "    elif label == 'Negative':\n",
        "      num = 1\n",
        "    elif label == 'Neutral':\n",
        "      num = 2\n",
        "    elif label == 'Extremely Positive':\n",
        "      num = 3\n",
        "    elif label == 'Extremely Negative':\n",
        "      num = 4\n",
        "    return num"
      ],
      "metadata": {
        "id": "UsJOziizWhfk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sentiment_num'] = data['Sentiment'].apply(lambda x : transform_labels(x))"
      ],
      "metadata": {
        "id": "3acszQBhWqIQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['UserName', 'ScreenName', 'Location', 'Sentiment'], axis=1)"
      ],
      "metadata": {
        "id": "W5PgxHHCXHZz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lI5hFSrXmk6",
        "outputId": "fdf108a9-e6e3-4192-c44b-0d3804a4c7e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41157 entries, 0 to 41156\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   TweetAt        41157 non-null  object\n",
            " 1   OriginalTweet  41157 non-null  object\n",
            " 2   Sentiment_num  41157 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 964.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data['OriginalTweet'].values\n",
        "y = data['Sentiment_num'].values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "metadata": {
        "id": "Mbmkr4qCXdu1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "In the bag-of-words model, a text is represented as the bag of its words, disregarding grammar and word order. Therefore, we will want to remove stop words, punctuations and characters that don't contribute much to the sentence's meaning."
      ],
      "metadata": {
        "id": "74oK6BO4YXIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVtjuQLkZNP0",
        "outputId": "bcf48b46-711d-4f11-9ac9-0c535601b953"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "1v3cGsLgZQsD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "FmfvkIUBYjch"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub('\"', '', newString)\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(' ')])\n",
        "    newString = re.sub(r\"’s\\b\", \"\", newString)\n",
        "    newString = re.sub('[^a-zA-Z\\s\\-]', '', newString)\n",
        "    newString = re.sub('[^a-zA-Z\\s]', ' ', newString)\n",
        "    tokens = [w for w in newString.split() if w not in stopwords]\n",
        "    long_words = []\n",
        "    prev_word = []\n",
        "    for i in tokens:\n",
        "        if i not in prev_word and len(i) >= 3:  # removing short word\n",
        "            long_words.append(i)\n",
        "            prev_word = [i]\n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "metadata": {
        "id": "YeKebGLIXqsk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In information retrieval, TF-IDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. We will use TF-IDF to vectorize our text data before feeding them to machine learning algorithms."
      ],
      "metadata": {
        "id": "sNMk_Vm9YxJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "X_train_preprocessed = np.array([text_cleaner(text) for text in X_train])\n",
        "X_val_preprocessed = np.array([text_cleaner(text) for text in X_val])\n",
        "# Calculate TF-IDF\n",
        "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
        "                         binary=True,\n",
        "                         smooth_idf=False, min_df=5)\n",
        "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
        "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
      ],
      "metadata": {
        "id": "V8yWKq77YpXp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjCDOYgZZU4o",
        "outputId": "4c0146b3-a1a4-42bc-acd7-966a90ef26b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<37041x24929 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 758228 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline with ML Algorithm - NB, SVM, etc."
      ],
      "metadata": {
        "id": "WUdjFzs1XMWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "metadata": {
        "id": "KZ59jBcD81vn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsa = TruncatedSVD(2, algorithm = 'arpack')\n",
        "dtm_lsa = lsa.fit_transform(X_train_tfidf)\n",
        "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)"
      ],
      "metadata": {
        "id": "yQIri3PQPnSd"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dtm_lsa, columns = ['component_1','component_2'])"
      ],
      "metadata": {
        "id": "3-T8BA52Pzmc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.scatter(df['component_1'],df['component_2'])\n",
        "plt.xlabel('First principal component')\n",
        "plt.ylabel('Second principal component')\n",
        "plt.title('Plot of points against LSA principal components')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ze0OYON5QNhM",
        "outputId": "8725f022-6544-404e-a6ee-b37cbedb540e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "6pXVkmKnZUDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "hQ3XlNuccx0t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTG0j5arYNPS",
        "outputId": "3ab392c1-b967-4660-bb37-39a11198b1f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_categories = model.predict(X_val_tfidf)"
      ],
      "metadata": {
        "id": "cQj8hnWoY0bD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "sns.set() # use seaborn plotting style"
      ],
      "metadata": {
        "id": "H4GwqEcQZDkM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the confusion matrix\n",
        "mat = confusion_matrix(y_val, predicted_categories)\n",
        "sns.heatmap(mat.T, square = True, annot=True, fmt = \"d\")\n",
        "plt.xlabel(\"true labels\")\n",
        "plt.ylabel(\"predicted label\")\n",
        "plt.show()\n",
        "print(\"The accuracy is {}\".format(accuracy_score(y_val, predicted_categories)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "60zI65BwYwIm",
        "outputId": "45f7637f-4973-4162-ed01-05939dba575b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 0.4402332361516035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "-8jcLtM9anPM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsa = TruncatedSVD(10)\n",
        "svc = SVC(kernel='rbf',class_weight='balanced')"
      ],
      "metadata": {
        "id": "v9IbK3TyZkup"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(lsa, svc)"
      ],
      "metadata": {
        "id": "h2sWotgzadNL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'svc__C': [1,5,10,50], 'svc__gamma': [0.0001,0.0005,0.001,0.005]}\n",
        "grid = GridSearchCV(model, param_grid)\n",
        "grid.fit(X_train_tfidf, y_train)\n",
        "print(grid.best_params_)"
      ],
      "metadata": {
        "id": "BLO2XQzKcWlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Tokenizing and Fine-Tuned BERT"
      ],
      "metadata": {
        "id": "qxuYvqhcdIMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "CRjwaMCFdJQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to apply the pre-trained BERT, we must use the tokenizer provided by the library. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words."
      ],
      "metadata": {
        "id": "pbVA7g16dUle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "cxIGX4AfdN4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "-zT8mFaKdWy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate train data and test data\n",
        "all_tweets = np.concatenate([data.tweet.values, test_data.tweet.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "metadata": {
        "id": "hbyYXmfndY2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "metadata": {
        "id": "rTfoeJDZeJHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT-base consists of 12 transformer layers, each transformer layer takes in a list of token embeddings, and produces the same number of embeddings with the same hidden size (or dimensions) on the output. The output of the final transformer layer of the [CLS] token is used as the features of the sequence to feed a classifier."
      ],
      "metadata": {
        "id": "hzpb7IwidqPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transformers library has the BertForSequenceClassification class which is designed for classification tasks. However, we will create a new class so we can specify our own choice of classifiers.\n",
        "\n",
        "Below we will create a BertClassifier class with a BERT model to extract the last hidden layer of the [CLS] token and a single-hidden-layer feed-forward neural network as our classifier."
      ],
      "metadata": {
        "id": "Dlgjv-_Odq6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits        "
      ],
      "metadata": {
        "id": "-lj_T67_d0Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT from Scratch / Encoder-only Attention Model"
      ],
      "metadata": {
        "id": "Z1ODakYZZnG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaAhsCwTMqZz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import re\n",
        "from random import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "        'Hello, how are you? I am Romeo.\\n'\n",
        "        'Hello, Romeo My name is Juliet. Nice to meet you.\\n'\n",
        "        'Nice meet you too. How are you today?\\n'\n",
        "        'Great. My baseball team won the competition.\\n'\n",
        "        'Oh Congratulations, Juliet\\n'\n",
        "        'Thanks you Romeo'\n",
        "    )"
      ],
      "metadata": {
        "id": "e-CZp3kjM2OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')  # filter '.', ',', '?', '!'\n",
        "word_list = list(set(\" \".join(sentences).split()))\n",
        "word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
        "\n",
        "\n",
        "for i, w in enumerate(word_list):\n",
        "    word_dict[w] = i + 4\n",
        "number_dict = {i: w for i, w in enumerate(word_dict)}\n",
        "vocab_size = len(word_dict)\n",
        "\n",
        "token_list = list()\n",
        "for sentence in sentences:\n",
        "    arr = [word_dict[s] for s in sentence.split()]\n",
        "    token_list.append(arr)"
      ],
      "metadata": {
        "id": "jDpK-QYuM3iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 30 # maximum of length\n",
        "batch_size = 6\n",
        "max_pred = 5  # max tokens of prediction\n",
        "n_layers = 6 # number of Encoder of Encoder Layer\n",
        "n_heads = 12 # number of heads in Multi-Head Attention\n",
        "d_model = 768 # Embedding Size\n",
        "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
        "d_k = d_v = 64  # dimension of K(=Q), V\n",
        "n_segments = 2\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "zSJQ-K3PM5xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batch():\n",
        "    batch = []\n",
        "    positive = negative = 0\n",
        "    while positive != batch_size/2 or negative != batch_size/2:\n",
        "        tokens_a_index, tokens_b_index= randrange(len(sentences)), randrange(len(sentences))\n",
        "        tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
        "\n",
        "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
        "\n",
        "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        #MASK LM\n",
        "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence\n",
        "\n",
        "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
        "                          if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
        "        shuffle(cand_maked_pos)\n",
        "        masked_tokens, masked_pos = [], []\n",
        "        for pos in cand_maked_pos[:n_pred]:\n",
        "            masked_pos.append(pos)\n",
        "            masked_tokens.append(input_ids[pos])\n",
        "            if random() < 0.8:  # 80%\n",
        "                input_ids[pos] = word_dict['[MASK]'] # make mask\n",
        "            elif random() < 0.5:  # 10%\n",
        "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
        "                input_ids[pos] = word_dict[number_dict[index]] # replace\n",
        "\n",
        "        # Zero Paddings\n",
        "        n_pad = maxlen - len(input_ids)\n",
        "        input_ids.extend([0] * n_pad)\n",
        "        segment_ids.extend([0] * n_pad)\n",
        "\n",
        "    #     # Zero Padding (100% - 15%) tokens\n",
        "        if max_pred > n_pred:\n",
        "            n_pad = max_pred - n_pred\n",
        "            masked_tokens.extend([0] * n_pad)\n",
        "            masked_pos.extend([0] * n_pad)\n",
        "\n",
        "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
        "            positive += 1\n",
        "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
        "            negative += 1\n",
        "\n",
        "    return batch"
      ],
      "metadata": {
        "id": "3BgSaf-sM7sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
      ],
      "metadata": {
        "id": "jCeNn0NfM_cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = make_batch()"
      ],
      "metadata": {
        "id": "JqGZgCAhy0Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(tf.constant, zip(*batch))"
      ],
      "metadata": {
        "id": "5ThwN4Zny1Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "id": "9W61s2R21v62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = tf.keras.layers.Embedding(vocab_size, d_model)  # token embedding\n",
        "        self.pos_embed = tf.keras.layers.Embedding(maxlen, d_model)  # position embedding\n",
        "        self.seg_embed = tf.keras.layers.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
        "        self.norm = layers.LayerNormalization(d_model)\n",
        "\n",
        "    def forward(self, x, seg):\n",
        "        seq_len = x.size(1)\n",
        "        pos = tf.experimental.numpy.arange(seq_len)\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
        "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "        return self.norm(embedding)"
      ],
      "metadata": {
        "id": "0lj_NGXaCSLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q,k,v,mask):\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention = matmul_qk / tf.math.sqrt(dk)\n",
        "  # add the mask\n",
        "  if mask is not None:\n",
        "    scaled_attention += (mask * -1e9)\n",
        "  \n",
        "  attention_weights = tf.nn.softmax(scaled_attention, axis=-1)\n",
        "  output = tf.matmul(attention_weights, v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "metadata": {
        "id": "H87F-c7wNDdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0,2,1,3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "GbKdG3UkNi7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model)\n",
        "  ])"
      ],
      "metadata": {
        "id": "U32JH2Hb2OpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, d_model, FFN_units, n_heads, dropout_rate):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.dropout_rate = dropout_rate\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        # Build the multihead layer\n",
        "        self.multi_head_attention = MultiHeadAttention(self.d_model, self.n_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(self.d_model, self.FFN_units)\n",
        "\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        \n",
        "    def call(self, inputs, mask, training):\n",
        "        # Forward pass of the multi-head attention\n",
        "        attn_output, _ = self.multi_head_attention(inputs,\n",
        "                                              inputs,\n",
        "                                              inputs,\n",
        "                                              mask)\n",
        "        attn_output = self.dropout_1(attn_output, training=training)\n",
        "        attn_output = self.norm_1(attn_output + inputs)\n",
        "        outputs = self.ffn(attn_output)\n",
        "        outputs = self.dropout_2(outputs, training=training)\n",
        "        outputs = self.norm_2(outputs + attn_output)\n",
        "        \n",
        "        return outputs"
      ],
      "metadata": {
        "id": "MSOHW8YMNlO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_gather(x, indices, gather_axis):\n",
        "    # if pytorch gather indices are\n",
        "    # [[[0, 10, 20], [0, 10, 20], [0, 10, 20]],\n",
        "    #  [[0, 10, 20], [0, 10, 20], [0, 10, 20]]]\n",
        "    # tf nd_gather needs to be\n",
        "    # [[0,0,0], [0,0,10], [0,0,20], [0,1,0], [0,1,10], [0,1,20], [0,2,0], [0,2,10], [0,2,20],\n",
        "    #  [1,0,0], [1,0,10], [1,0,20], [1,1,0], [1,1,10], [1,1,20], [1,2,0], [1,2,10], [1,2,20]]\n",
        "\n",
        "    # create a tensor containing indices of each element\n",
        "    all_indices = tf.where(tf.fill(indices.shape, True))\n",
        "    gather_locations = tf.reshape(indices, [indices.shape.num_elements()])\n",
        "\n",
        "    # splice in our pytorch style index at the correct axis\n",
        "    gather_indices = []\n",
        "    for axis in range(len(indices.shape)):\n",
        "        if axis == gather_axis:\n",
        "            gather_indices.append(gather_locations)\n",
        "        else:\n",
        "            gather_indices.append(all_indices[:, axis])\n",
        "\n",
        "    gather_indices = tf.stack(gather_indices, axis=-1)\n",
        "    gathered = tf.gather_nd(x, gather_indices)\n",
        "    reshaped = tf.reshape(gathered, indices.shape)\n",
        "    return reshaped"
      ],
      "metadata": {
        "id": "q0ZR5PbP91w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 FFN_units,\n",
        "                 n_heads,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"BERT\"):\n",
        "      \n",
        "        super(BERT, self).__init__(name=name)\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        self.embedding = Embedding()\n",
        "        self.layers = [EncoderLayer(d_model, FFN_units,\n",
        "                                        n_heads,\n",
        "                                        dropout_rate) \n",
        "                           for _ in range(n_layers)]\n",
        "        \n",
        "        self.fc = tf.keras.layers.Dense(d_model, input_shape=(d_model,), activation=None)\n",
        "        self.linear = tf.keras.layers.Dense(d_model, input_shape=(d_model,), activation=None)\n",
        "        self.norm = layers.LayerNormalization(d_model)\n",
        "        self.classifier = tf.keras.layers.Dense(2, input_shape=(d_model,), activation=None)\n",
        "        \n",
        "        # decoder is shared with embedding layer\n",
        "        embed_weight = self.embedding.tok_embed\n",
        "        self.decoder = tf.keras.layers.Dense(d_model, input_shape=(vocab_size,), activation=None)\n",
        "        self.decoder.weight = embed_weight\n",
        "        # self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
        "\n",
        "    def forward(self, input_ids, segment_ids, masked_pos, training):\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask, training)\n",
        "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
        "  \n",
        "        h_pooled = tf.math.tanh(self.fc(output[:, 0])) # [batch_size, d_model]\n",
        "        logits_clsf = self.classifier(h_pooled) # [batch_size, 2]\n",
        "\n",
        "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
        "        # get masked position from final output of transformer.\n",
        "        \n",
        "        h_masked = torch_gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
        "        h_masked = self.norm(tf.keras.activations.gelu(self.linear(h_masked)))\n",
        "        logits_lm = self.decoder(h_masked)\n",
        "\n",
        "        return logits_lm, logits_clsf"
      ],
      "metadata": {
        "id": "lHuCNf5N1_Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "khjQihLf-VDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERT(    \n",
        "    n_layers = n_layers,\n",
        "    d_model = d_model,\n",
        "    n_heads = n_heads,\n",
        "    FFN_units = d_ff,\n",
        "    vocab_size = vocab_size, \n",
        "    dropout_rate = dropout_rate)\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                                    from_logits=True, reduction='none')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "batch = make_batch()\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(tf.constant, zip(*batch))\n",
        "\n",
        "for epoch in range(10):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
        "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
        "    loss_lm = (loss_lm.float()).mean()\n",
        "    loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
        "    loss = loss_lm + loss_clsf\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "      print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "SJOwNsUy-Dcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}