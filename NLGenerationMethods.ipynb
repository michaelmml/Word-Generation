{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2PdQARJ52II/w+84VT1Cn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Markov Word Generator from Scratch\n",
        "\n",
        "As a starting point to understanding natural language processing and generation, I thought about text generation in a determinstic way, without machine learning, based on the exact words that follow from combination of words before in any given text. And the next words forms part of the combination that then generates the next word, and so on...\n",
        "\n",
        "From my mathematical background, this showed Markov properties which led me to consider how to build a transition matrix from all of this. My exposure to Python and data science at the time was solely with numerical data in Numpy or Pandas and so I approached this problem from that perspective.\n",
        "\n",
        "The first step is to load a corpus of text and clean the data, but preserving grammatical structure such that the Markov process will generate grammatically correct words at each step.\n",
        "\n",
        "I have then created a function to break the text into phrases of any length and the following word/phrase. This essentially creates a dataframe of a feature and a label of 10s of thousands of rows depending on the initial length of the text.\n",
        "\n"
      ],
      "metadata": {
        "id": "XiW0_7NNidVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICAvRhkgFY6m",
        "outputId": "22ac1455-4d6d-4a10-d350-f54e55160d90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9UVuG-cPGEoh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "IsZGqITEHOMD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = '/content/drive/My Drive/WordGeneration'"
      ],
      "metadata": {
        "id": "bxQeSI2-GIgF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(root_folder+'/FOMC2021.txt', sep=\"\\n\")"
      ],
      "metadata": {
        "id": "QDyMJUD8GOCJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns={\"Action to Adopt Changes to the Committee's Rules Regarding Availability of Information\": \"text\"},\n",
        "          inplace=True)\n",
        "data[\"text\"] = data[\"text\"].str.replace(\"United States\", \"US\")\n",
        "data[\"text\"] = data[\"text\"].str.replace(\"U.S.\", \"US\")\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Cwg3iuGdMC",
        "outputId": "223f631b-da91-460c-9474-c3e884b86b66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 486 entries, 0 to 485\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    486 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 3.9+ KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_text = 3\n",
        "len_result = 1"
      ],
      "metadata": {
        "id": "_vnlixQaG0-e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_folder = '/content/drive/My Drive/Colab Notebooks'"
      ],
      "metadata": {
        "id": "0xRM9siwIVCi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(func_folder)"
      ],
      "metadata": {
        "id": "gLBwTdWIIURA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Contractions\n",
        "from Contractions import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3Ix9QYNIXwi",
        "outputId": "cd250f3b-9a5e-4fb2-dbc0-9ca28f4f89db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "    text = re.sub('[0-9]+.\\t', '', str(text)) # removing paragraph numbers\n",
        "    text = re.sub('U.S.', 'USA', str(text))\n",
        "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(' ')])\n",
        "    text = re.sub('\\n ', '', str(text))\n",
        "    text = re.sub('\\n', ' ', str(text))\n",
        "    text = re.sub(\"'s\", '', str(text))\n",
        "    text = re.sub(\"-\", ' ', str(text))\n",
        "    text = re.sub(\"â€” \", '', str(text))\n",
        "    text = re.sub('\\\"', '', str(text))\n",
        "    text = re.sub(\"Mr\\.\", 'Mr', str(text))\n",
        "    text = re.sub(\"Mrs\\.\", 'Mrs', str(text))\n",
        "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(text))\n",
        "    text = re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', text) # add space around punctuation, i.e. treat them as token\n",
        "    text = re.sub(r'\\s\\s', ' ', text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "a9hLS4ypHJVx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_clean'] = data['text'].apply(clean)"
      ],
      "metadata": {
        "id": "HAYFlDtaIdEC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6yYHwp9i5ra_"
      },
      "outputs": [],
      "source": [
        "def sequence_generator(texts,\n",
        "                      training_length, \n",
        "                      result_length, \n",
        "                      max_train=100000,\n",
        "                      start_end_tokens=False,\n",
        "                      lower=True):\n",
        "\n",
        "    tokenizer = Tokenizer(lower=lower)\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "\n",
        "    word_idx = tokenizer.word_index\n",
        "    idx_word = tokenizer.index_word\n",
        "    num_words = len(word_idx) + 1\n",
        "    word_counts = tokenizer.word_counts\n",
        "\n",
        "    print(f'There are {num_words} unique words.')\n",
        "\n",
        "    # import pickle\n",
        "    # with open('tokenizer.pickle', 'wb') as handle:\n",
        "    #     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    # Start-End tokens\n",
        "    # x = word_idx[\"start_token\"]\n",
        "    # y = word_idx[\"end_token\"]\n",
        "\n",
        "    # Limit to sequences with more than training length tokens\n",
        "    seq_lengths = [len(x) for x in sequences]\n",
        "    over_idx = [\n",
        "        i for i, l in enumerate(seq_lengths) if l > (training_length + result_length + 3)]\n",
        "\n",
        "    new_texts = []\n",
        "    new_sequences = []\n",
        "\n",
        "    # Only keep sequences with more than training length tokens\n",
        "    for i in over_idx:\n",
        "        new_texts.append(texts[i])\n",
        "        new_sequences.append(sequences[i])\n",
        "\n",
        "    training_seq = []\n",
        "    labels = []\n",
        "    training_seq_words = []\n",
        "    labels_words = []\n",
        "\n",
        "    for seq in new_sequences:\n",
        "\n",
        "        if len(training_seq) < max_train:\n",
        "            for i in range(training_length, len(seq) - result_length):\n",
        "                # Extract the features and label\n",
        "                extract = seq[i - training_length:i + result_length]\n",
        "                training_seq.append(extract[:training_length])\n",
        "                if start_end_tokens:\n",
        "                    label_adj = [x] + extract[training_length:] + [y]\n",
        "                else: label_adj = extract[training_length:]\n",
        "                labels.append(label_adj)\n",
        "\n",
        "                training_seq_words.append([idx_word[j] for j in extract[:training_length]])\n",
        "                labels_words.append([idx_word[j] for j in extract[training_length:]])\n",
        "\n",
        "    print(f'There are {len(training_seq)} training sequences.')\n",
        "\n",
        "    return word_idx, idx_word, num_words, word_counts, new_texts, new_sequences, training_seq, labels, \\\n",
        "           training_seq_words, labels_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_idx, idx_word, num_words, word_counts, new_texts, sequences, features, labels, training_seq_words, labels_words = \\\n",
        "    sequence_generator(\n",
        "    data['text_clean'].tolist(), training_length = len_text, result_length = len_result, lower=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx5GhElBHQ16",
        "outputId": "6b08e394-cd65-4592-d899-bfcfb01d0b9c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2954 unique words.\n",
            "There are 55802 training sequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'features': training_seq_words, 'labels': labels_words})"
      ],
      "metadata": {
        "id": "xKVVoaJzL-NP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['labels'] = df['labels'].map(lambda x: x[0])"
      ],
      "metadata": {
        "id": "61dTriZmM2Yg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hmGgxfZQNrag",
        "outputId": "2e84b9cc-be28-47e9-bf49-7e3d8a55c651"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             features         labels\n",
              "0               [by, unanimous, vote]            the\n",
              "1              [unanimous, vote, the]      committee\n",
              "2              [vote, the, committee]       approved\n",
              "3          [the, committee, approved]              a\n",
              "4            [committee, approved, a]          final\n",
              "...                               ...            ...\n",
              "55797     [pressures, and, inflation]   expectations\n",
              "55798  [and, inflation, expectations]            and\n",
              "55799  [inflation, expectations, and]      financial\n",
              "55800  [expectations, and, financial]            and\n",
              "55801           [and, financial, and]  international\n",
              "\n",
              "[55802 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b0406f8-bbb5-4734-9d9f-2f88249d0f0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[by, unanimous, vote]</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[unanimous, vote, the]</td>\n",
              "      <td>committee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[vote, the, committee]</td>\n",
              "      <td>approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[the, committee, approved]</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[committee, approved, a]</td>\n",
              "      <td>final</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55797</th>\n",
              "      <td>[pressures, and, inflation]</td>\n",
              "      <td>expectations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55798</th>\n",
              "      <td>[and, inflation, expectations]</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55799</th>\n",
              "      <td>[inflation, expectations, and]</td>\n",
              "      <td>financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55800</th>\n",
              "      <td>[expectations, and, financial]</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55801</th>\n",
              "      <td>[and, financial, and]</td>\n",
              "      <td>international</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55802 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b0406f8-bbb5-4734-9d9f-2f88249d0f0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b0406f8-bbb5-4734-9d9f-2f88249d0f0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b0406f8-bbb5-4734-9d9f-2f88249d0f0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Transition Matrix\n",
        "\n",
        "The following can be made more Pythonic but it was intuitive to set out each change step by step. First, one-hot encoding is done of the labels to create a dataframe with columns equal to the number of unique vocabulary.\n",
        "\n",
        "Secondly, groupby operation is used on the features phrase (in this case a three word phrase) to group by number of instances of each phrase and a count of the word that follows.\n",
        "\n",
        "Dividing each row by the total of that row creates a probability distribution of the word that follows the three word phrase corresponding to that row. This is our transition matrix."
      ],
      "metadata": {
        "id": "xYTVewii26DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "markov_matrix = pd.concat([df, pd.get_dummies(df['labels'])], axis=1)"
      ],
      "metadata": {
        "id": "t7Pieoc9OZl9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_matrix = markov_matrix.drop(['labels'], axis=1)"
      ],
      "metadata": {
        "id": "2vzjG3O1QS7p"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_matrix['features'] = markov_matrix['features'].apply(\" \".join)"
      ],
      "metadata": {
        "id": "4fw_wFgOQ5yl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix = markov_matrix.groupby('features',as_index=False)[markov_matrix.columns.tolist()].sum()"
      ],
      "metadata": {
        "id": "KBisDV6AU0IR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transition_matrix = transition_matrix.div(transition_matrix.sum(axis=1), axis=0)"
      ],
      "metadata": {
        "id": "wdr2glWL9fjA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_dict = transition_matrix['features'].to_dict()\n",
        "word_dict = dict(enumerate(transition_matrix.columns.tolist()))"
      ],
      "metadata": {
        "id": "38004VgCW13k"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_dict_reversed = {v: k for k, v in phrase_dict.items()}"
      ],
      "metadata": {
        "id": "URmSwpGPbuhS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse"
      ],
      "metadata": {
        "id": "bbbyVnUPLZOq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.sparse.to_coo(transition_matrix)\n",
        "transition_matrix = sparse.csr_matrix(transition_matrix.to_coo())"
      ],
      "metadata": {
        "id": "AiEGjubBIXJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Words\n",
        "\n",
        "To use our transition matrix, we create dictionaries of the phrases and its index as well as the vocabulary and its index in the transition matrix. Given a phrase, the index of the row is located and the np.random.choice generates the following word weighted by the probabilities in that row. The other function then appends the word to our generated sentence and extracts the last three-word-phrase to loop through the process as many times as defined."
      ],
      "metadata": {
        "id": "pcZpsUZ-3xu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_weights_temperature(input_weights, temperature):\n",
        "    weights = np.where(input_weights == 0, 0, np.log(input_weights + 1e-10)) / temperature\n",
        "    weights = np.exp(weights)\n",
        "    return weights / np.sum(weights)"
      ],
      "metadata": {
        "id": "8myNbiYRWYkJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_next_word(prefix, temperature=1):\n",
        "    prefix_ind = phrase_dict_reversed[prefix]\n",
        "    weights = transition_matrix.iloc[prefix_ind].values[1:].astype('float64')\n",
        "    prob = weights / sum(weights)\n",
        "    if temperature != 1:\n",
        "        weights = add_weights_temperature(prob, temperature)\n",
        "\n",
        "    token_ind = np.random.choice(range(len(weights)), p=prob)+1\n",
        "    next_word = word_dict[token_ind]\n",
        "    return next_word"
      ],
      "metadata": {
        "id": "ORWw-ufuUQ-p"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_words(seed, length):\n",
        "    next_word = return_next_word(seed)\n",
        "    sentence = seed.split()\n",
        "    \n",
        "    for i in range(length):\n",
        "        sentence.append(next_word)\n",
        "        next_word = return_next_word(\" \".join(sentence[-3:]))\n",
        "    \n",
        "    return \" \".join(sentence)"
      ],
      "metadata": {
        "id": "YaQr2AXYUmc-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_words(\"accumulated by households\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "8ciZpuQxekxQ",
        "outputId": "eb3ba3eb-8b53-467b-c9b2-f358439f134e"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"accumulated by households since the beginning of the period to negotiations on the debt limit by 480 billion market participants' estimates of the new date when the treasury would exhaust its extraordinary measures and cash balance were wide ranging but some estimates suggested the date might be as early as mid december most market participants anticipated adjustments to the pace of purchases if warranted by changes in the composition of the federal reserve bank of new york until instructed otherwise to execute transactions in the soma in accordance with the committee assessments of maximum employment and inflation and posed considerable risks to the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_words(\"early as mid\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "DGwNC9eMiUY0",
        "outputId": "229cc4db-820a-456f-9d40-046a19e64376"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'early as mid december most market participants anticipated that the economy were to evolve broadly as they anticipated they judged that the release of pent up demand could boost consumption growth further as social distancing restrictions were imposed to rein in a new wave of covid 19 in the us amid this progress and strong policy support indicators of economic activity and employment had continued to surge and expected that it would likely be appropriate in each subsequent month some participants preferred a somewhat faster pace of reductions that would result in reducing the monthly pace of the recovery indicators of economic activity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transition_matrix(self):\n",
        "    row_ind, col_ind, values = [], [], []\n",
        "\n",
        "    for i in range(len(self.tokens[:-self.n])):\n",
        "        ngram = ' '.join(self.tokens[i:i + self.n])\n",
        "        ngram_ind = self.ngram2ind[ngram]\n",
        "        next_word_ind = self.token2ind[self.tokens[i + self.n]]\n",
        "\n",
        "        row_ind.extend([ngram_ind])\n",
        "        col_ind.extend([next_word_ind])\n",
        "        values.extend([1])\n",
        "\n",
        "    S = scipy.sparse.coo_matrix((values, (row_ind, col_ind)), shape=(len(self.ngram2ind), len(self.token2ind)))\n",
        "    return S"
      ],
      "metadata": {
        "id": "bfaozeChGLt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Deep Learning Model\n",
        "\n",
        "Moving on into Deep Learning, we approach this from the perspective of a many-to-one sequence problem. In much of the same way, we generate our features sequences and labels as numpy arrays. We then also one-hot encode the features.\n",
        "\n",
        "The next step is where the earlier-completed tokenization comes into play as we also need to create an embedding for the words. In essence, an embedding is a vector representation of words and their relative distance to other words. There are existing embeddings such as GloVe which have been trained a much larger datasets and can be imported. Otherwise, we can train our own embedding."
      ],
      "metadata": {
        "id": "gt0uYD8n5BX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len_text = 30\n",
        "len_result = 1"
      ],
      "metadata": {
        "id": "iffVvv8qwAJw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_idx, idx_word, num_words, word_counts, new_texts, sequences, features, labels, training_seq_words, labels_words = \\\n",
        "    sequence_generator(\n",
        "    data['text_clean'].tolist(), training_length = len_text, result_length = len_result, lower=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHQNwP5ZwGYk",
        "outputId": "56af197a-53a3-4ec8-dacf-8ec9888eabbe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2953 unique words.\n",
            "There are 43934 training sequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_FRACTION = 0.7\n",
        "RANDOM_STATE = 50"
      ],
      "metadata": {
        "id": "jCgpniopwgrP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "qQvW9vDgwob5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_valid(features,\n",
        "                       labels,\n",
        "                       num_words,\n",
        "                       train_fraction=TRAIN_FRACTION):\n",
        "\n",
        "    features, labels = shuffle(features, labels, random_state=RANDOM_STATE)\n",
        "    train_end = int(train_fraction * len(labels))\n",
        "\n",
        "    train_features = np.array(features[:train_end])\n",
        "    valid_features = np.array(features[train_end:])\n",
        "\n",
        "    train_labels = labels[:train_end]\n",
        "    valid_labels = labels[train_end:]\n",
        "\n",
        "    # Convert to arrays\n",
        "    X_train, X_valid = np.array(train_features), np.array(valid_features)\n",
        "\n",
        "    y_train = np.zeros((len(train_labels), num_words), dtype=np.int8)\n",
        "    y_valid = np.zeros((len(valid_labels), num_words), dtype=np.int8)\n",
        "\n",
        "    # numpy array with one-hot encoding consisting of number of training data \n",
        "    # and size of vocabulary with 1 at the corresponding word following from the features\n",
        "    for example_index, word_index in enumerate(train_labels):\n",
        "        y_train[example_index, word_index] = 1\n",
        "\n",
        "    for example_index, word_index in enumerate(valid_labels):\n",
        "        y_valid[example_index, word_index] = 1\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid"
      ],
      "metadata": {
        "id": "pLxfDJDO5A0j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = create_train_valid(\n",
        "    features, labels, num_words)"
      ],
      "metadata": {
        "id": "Ut6d4CbSC0Oi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained Embedding with GloVe (Optional)"
      ],
      "metadata": {
        "id": "VaQ9PYFkDBud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove = np.loadtxt('glove.6B.100d.txt', dtype='str', comments=None, encoding=\"utf8\")\n",
        "print(glove.shape)\n",
        "vectors = glove[:, 1:].astype('float')\n",
        "words = glove[:, 0]\n",
        "del glove"
      ],
      "metadata": {
        "id": "IPy2tYLVC8ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_lookup = {word: vector for word, vector in zip(words, vectors)}\n",
        "embedding_matrix = np.zeros((num_words, vectors.shape[1]))"
      ],
      "metadata": {
        "id": "8gdo1ZSiDETd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_found = 0"
      ],
      "metadata": {
        "id": "FMUnlkVoxF_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, word in enumerate(word_idx.keys()):\n",
        "    vector = word_lookup.get(word, None)\n",
        "\n",
        "    if vector is not None:\n",
        "        embedding_matrix[i + 1, :] = vector\n",
        "    else:\n",
        "        not_found += 1"
      ],
      "metadata": {
        "id": "0XDIVI4kDHSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = embedding_matrix / \\\n",
        "    np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n",
        "embedding_matrix = np.nan_to_num(embedding_matrix)"
      ],
      "metadata": {
        "id": "o-uuWFgjDilN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest(query, embedding_matrix, word_idx, idx_word, n=10):\n",
        "\n",
        "    idx = word_idx.get(query, None)\n",
        "    if idx is None:\n",
        "        print(f'{query} not found in vocab.')\n",
        "        return\n",
        "    else:\n",
        "        vec = embedding_matrix[idx]\n",
        "        if np.all(vec == 0):\n",
        "            print(f'{query} has no pre-trained embedding.')\n",
        "            return\n",
        "        else:\n",
        "            # Calculate distance between vector and all others\n",
        "            dists = np.dot(embedding_matrix, vec)\n",
        "\n",
        "            idxs = np.argsort(dists)[::-1][:n]\n",
        "            sorted_dists = dists[idxs]\n",
        "            closest = [idx_word[i] for i in idxs]\n",
        "\n",
        "    print(f'Query: {query}\\n')\n",
        "    max_len = max([len(i) for i in closest])\n",
        "    for word, dist in zip(closest, sorted_dists):\n",
        "        print(f'Word: {word:15} Cosine Similarity: {round(dist, 4)}')"
      ],
      "metadata": {
        "id": "P-eLo6miDmPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training LSTM Model\n",
        "\n",
        "Whether or not we have the pre-trained embeddings, we approach this problem based on the sequence of words, which is however long we specify and earch further represented by the dimensions of the embedding.\n",
        "\n",
        "We can train a recurrent neural network with one or several layers on these token sequences with embeddings to predict the label, i.e. the token/word that follows."
      ],
      "metadata": {
        "id": "u2bihDfbw9cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_CELLS = 64\n",
        "embedding_dim = 200\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 2048\n",
        "VERBOSE = 0"
      ],
      "metadata": {
        "id": "hd1WTCZpzGB6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "0Wzh2ODX7yxy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional"
      ],
      "metadata": {
        "id": "W1VpSK4BDoBh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "TAYUg4IPDpoi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, trainable=True))"
      ],
      "metadata": {
        "id": "cComd8_dxmSL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(LSTM(LSTM_CELLS, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))"
      ],
      "metadata": {
        "id": "qPK31jBOxsL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(LSTM(LSTM_CELLS, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))"
      ],
      "metadata": {
        "id": "yxdRzWF9z7Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Bidirectional(LSTM(LSTM_CELLS, return_sequences=False, dropout=0.1, recurrent_dropout=0.1)))"
      ],
      "metadata": {
        "id": "4PEiD8f_zJEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(num_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "IwnHqhk_zc9u"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MPImTde2zhiN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ZDoC3wzklg",
        "outputId": "3d86d2c3-1bd2-4e6c-e3d3-688f6a6f8aa5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 200)         590600    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, None, 64)          67840     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, None, 64)          33024     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              66048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2953)              380937    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,138,449\n",
            "Trainable params: 1,138,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "7waQ2a-W_DmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=VERBOSE,\n",
        "    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "KyWv3rNNz6kP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RDzU5n335HEx",
        "outputId": "29ec6381-3c89-43eb-a6fb-8b0ac439b76e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(root_folder+'/BiLSTMNLG', save_format='tf')"
      ],
      "metadata": {
        "id": "nEM7K1zq5VLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "7-nTTnsk-xJ9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = Sequential()\n",
        "load_model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, trainable=True))\n",
        "load_model.add(LSTM(LSTM_CELLS, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "load_model.add(LSTM(LSTM_CELLS, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "load_model.add(Bidirectional(LSTM(LSTM_CELLS, return_sequences=False, dropout=0.1, recurrent_dropout=0.1)))\n",
        "load_model.add(Dense(num_words, activation='softmax'))\n",
        "load_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y6ReYuQK_OQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model.load_weights(root_folder+'/BiLSTMNLG')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9yu6Pfr_PMc",
        "outputId": "4bfcc15d-2237-4a7a-b2b1-216f81d15815"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd197816490>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = load_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=VERBOSE,\n",
        "    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "0SgFQzVE7PrB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = load_model.evaluate(X_valid, y_valid, batch_size=2048, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zH1mEe9BXE_",
        "outputId": "6d672d49-322f-48cb-f6bd-b3e58f8c9b4f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 116ms/step - loss: 6.1994 - accuracy: 0.0676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "P3WzrJQ_C7vn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(model,\n",
        "                    sequences,\n",
        "                    training_length=len_text,\n",
        "                    new_words=50,\n",
        "                    diversity=1,\n",
        "                    return_output=False,\n",
        "                    n_gen=1):\n",
        "\n",
        "    seq = random.choice(sequences)\n",
        "    seed_idx = random.randint(0, len(seq) - training_length - 10)\n",
        "    end_idx = seed_idx + training_length\n",
        "\n",
        "    gen_list = []\n",
        "\n",
        "    for n in range(n_gen):\n",
        "        # Extract the seed sequence\n",
        "        seed = seq[seed_idx:end_idx]\n",
        "        original_sequence = [idx_word[i] for i in seed]\n",
        "        generated = seed[:] + ['#']\n",
        "\n",
        "        actual = generated[:] + seq[end_idx:end_idx + new_words]\n",
        "\n",
        "        for i in range(new_words):\n",
        "\n",
        "            preds = model.predict(np.array(seed).reshape(1, -1))[0].astype(\n",
        "                np.float64)\n",
        "\n",
        "            preds = np.log(preds) / diversity\n",
        "            exp_preds = np.exp(preds)\n",
        "\n",
        "            # Softmax\n",
        "            preds = exp_preds / sum(exp_preds)\n",
        "\n",
        "            # Choose the next word\n",
        "            probas = np.random.multinomial(1, preds, 1)[0]\n",
        "\n",
        "            next_idx = np.argmax(probas)\n",
        "\n",
        "            # New seed adds on old word\n",
        "            seed = seed[1:] + [next_idx]\n",
        "            generated.append(next_idx)\n",
        "\n",
        "        # Showing generated and actual abstract\n",
        "        n = []\n",
        "\n",
        "        for i in generated:\n",
        "            n.append(idx_word.get(i, '< --- >'))\n",
        "\n",
        "        gen_list.append(n)\n",
        "\n",
        "    a = []\n",
        "\n",
        "    for i in actual:\n",
        "        a.append(idx_word.get(i, '< --- >'))\n",
        "\n",
        "    a = a[training_length:]\n",
        "\n",
        "    gen_list = [\n",
        "        gen[training_length:training_length + len(a)] for gen in gen_list\n",
        "    ]\n",
        "\n",
        "    return ' '.join(original_sequence), ' '.join(gen_list[0]), ' '.join(a)"
      ],
      "metadata": {
        "id": "ym2iRVPWCT9O"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(load_model, sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYooKkRxDxEM",
        "outputId": "1e99442c-e148-4692-bb3d-aa694f59213b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('remained accommodative consumer credit jumped in may and remained strong in june reflecting a rebound in credit card balances and continued robust growth in auto loans banks in the july',\n",
              " '< --- > inflation distribution rate reviewed time firms low treasury recovery chinese in the to market winding adaptation net weigh',\n",
              " '< --- > sloos reported stronger demand and easier standards for both credit cards and auto loans over the second quarter')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With GPT2"
      ],
      "metadata": {
        "id": "rIUwjhOREM8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "2zX16eUzEXk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=train_path,\n",
        "    block_size=128)\n",
        "     \n",
        "test_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=test_path,\n",
        "    block_size=128)"
      ],
      "metadata": {
        "id": "flZC6DTlEYCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "nMDLl9ReEa2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = 'data/out', # the output directory for the model predictions and checkpoints\n",
        "    overwrite_output_dir = True, # overwrite the content of the output directory\n",
        "    per_device_train_batch_size = 32, # the batch size for training\n",
        "    per_device_eval_batch_size = 32, # the batch size for evaluation\n",
        "    learning_rate = 5e-5, # defaults to 5e-5\n",
        "    num_train_epochs = 3, # total number of training epochs to perform\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "lwlP5eFlEdwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}